{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "Python 3.7.2\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "print(lgb.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. _Data preparation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(65265, 50), (65265,), (21755, 50), (21755,)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.read_csv('../../03-boosting/train_medium.csv')\n",
    "y_train = X_train['Disbursed']\n",
    "\n",
    "X_test = pd.read_csv('../../03-boosting/test_medium.csv')\n",
    "y_test = X_test['Disbursed']\n",
    "\n",
    "X_train, X_test = [ x.drop('Disbursed', 1) for x in [X_train, X_test] ]\n",
    "\n",
    "[ a.shape for a in [X_train, y_train, X_test, y_test] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      47\n",
       "float64     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    21431\n",
       "1.0      324\n",
       "Name: Disbursed, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Existing_EMI</th>\n",
       "      <th>Loan_Amount_Applied</th>\n",
       "      <th>Loan_Tenure_Applied</th>\n",
       "      <th>Monthly_Income</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Age</th>\n",
       "      <th>EMI_Loan_Submitted_Missing</th>\n",
       "      <th>Interest_Rate_Missing</th>\n",
       "      <th>...</th>\n",
       "      <th>Var2_2</th>\n",
       "      <th>Var2_3</th>\n",
       "      <th>Var2_4</th>\n",
       "      <th>Var2_5</th>\n",
       "      <th>Var2_6</th>\n",
       "      <th>Mobile_Verified_0</th>\n",
       "      <th>Mobile_Verified_1</th>\n",
       "      <th>Source_0</th>\n",
       "      <th>Source_1</th>\n",
       "      <th>Source_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29000</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64000</td>\n",
       "      <td>3832.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25000</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22500</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17943</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Existing_EMI  Loan_Amount_Applied  Loan_Tenure_Applied  \\\n",
       "0        7881           0.0             100000.0                  3.0   \n",
       "1         189       21000.0             450000.0                  5.0   \n",
       "2       64000        3832.0             100000.0                  3.0   \n",
       "3       61629           0.0             200000.0                  3.0   \n",
       "4       23212           0.0              50000.0                  1.0   \n",
       "\n",
       "   Monthly_Income  Var4  Var5  Age  EMI_Loan_Submitted_Missing  \\\n",
       "0           29000     4    11   29                           0   \n",
       "1           48000     1     0   27                           1   \n",
       "2           25000     5    11   44                           0   \n",
       "3           22500     3     1   26                           1   \n",
       "4           17943     1     0   25                           1   \n",
       "\n",
       "   Interest_Rate_Missing    ...     Var2_2  Var2_3  Var2_4  Var2_5  Var2_6  \\\n",
       "0                      0    ...          0       0       0       0       0   \n",
       "1                      1    ...          0       0       0       0       0   \n",
       "2                      0    ...          0       0       0       0       1   \n",
       "3                      1    ...          0       0       0       0       1   \n",
       "4                      1    ...          0       0       0       0       0   \n",
       "\n",
       "   Mobile_Verified_0  Mobile_Verified_1  Source_0  Source_1  Source_2  \n",
       "0                  0                  1         0         1         0  \n",
       "1                  1                  0         0         1         0  \n",
       "2                  0                  1         1         0         0  \n",
       "3                  0                  1         1         0         0  \n",
       "4                  1                  0         0         1         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. _Basic classifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(num_leaves=30, learning_rate=0.05, n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=20, n_jobs=-1, num_leaves=30, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_test, y_test),\n",
    "    early_stopping_rounds=25,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(dataset_name, X, y_true, y_pred, y_proba):\n",
    "    print(\"[{}]\".format(dataset_name))\n",
    "    print(\"Accuracy : {:.3f}\".format(metrics.accuracy_score(y_true, y_pred)))\n",
    "    print(\"AUC Score: {:.3f}\".format(metrics.roc_auc_score(y_true, y_proba)))\n",
    "    print(metrics.classification_report(y_true, y_pred, digits=3))\n",
    "    print(60 * \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]\n",
      "Accuracy : 0.985\n",
      "AUC Score: 0.883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.985     1.000     0.993     64316\n",
      "         1.0      0.000     0.000     0.000       949\n",
      "\n",
      "   micro avg      0.985     0.985     0.985     65265\n",
      "   macro avg      0.493     0.500     0.496     65265\n",
      "weighted avg      0.971     0.985     0.978     65265\n",
      "\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test]\n",
      "Accuracy : 0.985\n",
      "AUC Score: 0.829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.985     1.000     0.992     21431\n",
      "         1.0      0.000     0.000     0.000       324\n",
      "\n",
      "   micro avg      0.985     0.985     0.985     21755\n",
      "   macro avg      0.493     0.500     0.496     21755\n",
      "weighted avg      0.970     0.985     0.978     21755\n",
      "\n",
      "************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roma\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"train\", X_train, y_train, model.predict(X_train), model.predict_proba(X_train)[:,1])\n",
    "\n",
    "print_scores(\"test\", X_test, y_test, model.predict(X_test), model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем, с объектами класса <b>1</b> тоже не справляется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Monthly_Income', 125),\n",
       " ('Unnamed: 0', 74),\n",
       " ('Var5', 66),\n",
       " ('Age', 58),\n",
       " ('Existing_EMI', 50),\n",
       " ('Loan_Amount_Applied', 46),\n",
       " ('Var4', 36),\n",
       " ('Loan_Tenure_Applied', 16),\n",
       " ('Source_2', 12),\n",
       " ('Source_0', 11),\n",
       " ('Var1_2', 11),\n",
       " ('Loan_Amount_Submitted_Missing', 10),\n",
       " ('Filled_Form_0', 10),\n",
       " ('Device_Type_0', 8),\n",
       " ('Source_1', 6),\n",
       " ('Var1_11', 6),\n",
       " ('Var1_3', 5),\n",
       " ('Gender_0', 5),\n",
       " ('Var1_9', 3),\n",
       " ('Var1_8', 3),\n",
       " ('Var2_2', 3),\n",
       " ('EMI_Loan_Submitted_Missing', 3),\n",
       " ('Var1_10', 2),\n",
       " ('Processing_Fee_Missing', 2),\n",
       " ('Var1_15', 2),\n",
       " ('Mobile_Verified_1', 2),\n",
       " ('Device_Type_1', 2),\n",
       " ('Filled_Form_1', 1),\n",
       " ('Var1_1', 1),\n",
       " ('Var1_5', 1),\n",
       " ('Interest_Rate_Missing', 0),\n",
       " ('Var2_0', 0),\n",
       " ('Var1_18', 0),\n",
       " ('Mobile_Verified_0', 0),\n",
       " ('Var2_6', 0),\n",
       " ('Var2_5', 0),\n",
       " ('Var2_4', 0),\n",
       " ('Var2_3', 0),\n",
       " ('Var1_17', 0),\n",
       " ('Var2_1', 0),\n",
       " ('Var1_0', 0),\n",
       " ('Loan_Tenure_Submitted_Missing', 0),\n",
       " ('Var1_14', 0),\n",
       " ('Var1_13', 0),\n",
       " ('Var1_12', 0),\n",
       " ('Var1_7', 0),\n",
       " ('Var1_6', 0),\n",
       " ('Var1_4', 0),\n",
       " ('Gender_1', 0),\n",
       " ('Var1_16', 0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_idx = np.argsort(model.feature_importances_)[::-1]\n",
    "\n",
    "list(zip(X_train.columns[feature_idx], model.feature_importances_[feature_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. _Hyperparams_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры, используя метрику, более ориентированную на **recall** для класса <b>1</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 2.\n",
    "\n",
    "fbeta_scorer = metrics.make_scorer(metrics.fbeta_score, pos_label=1, average='binary', beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate' : [0.1, 0.05, 0.01],\n",
    "    'num_leaves' : [30, 100, 500],\n",
    "    'n_estimators' : [10, 300]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(LGBMClassifier(random_seed=199), param_grid, scoring=fbeta_scorer, n_jobs=-1, iid=False, cv=5)\n",
    "\n",
    "gs.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=25, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.1, 'n_estimators': 300, 'num_leaves': 30},\n",
       " 0.010398371322383537)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gs.best_estimator_\n",
    "\n",
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=300, n_jobs=-1, num_leaves=30, objective=None,\n",
       "        random_seed=199, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "        silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "        subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]\n",
      "Accuracy : 0.986\n",
      "AUC Score: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.986     1.000     0.993     64316\n",
      "         1.0      0.846     0.012     0.023       949\n",
      "\n",
      "   micro avg      0.986     0.986     0.986     65265\n",
      "   macro avg      0.916     0.506     0.508     65265\n",
      "weighted avg      0.984     0.986     0.979     65265\n",
      "\n",
      "************************************************************\n",
      "[test]\n",
      "Accuracy : 0.985\n",
      "AUC Score: 0.832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.985     1.000     0.992     21431\n",
      "         1.0      0.250     0.003     0.006       324\n",
      "\n",
      "   micro avg      0.985     0.985     0.985     21755\n",
      "   macro avg      0.618     0.501     0.499     21755\n",
      "weighted avg      0.974     0.985     0.978     21755\n",
      "\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "print_scores(\"train\", X_train, y_train, model.predict(X_train), model.predict_proba(X_train)[:,1])\n",
    "\n",
    "print_scores(\"test\", X_test, y_test, model.predict(X_test), model.predict_proba(X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hемного удалось улучшить **recall** по классу <b>1</b>, но в целом тоже слабовато."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
