{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание:\n",
    "\n",
    "Для данных кредитного скоринга (https://raw.githubusercontent.com/gastonstat/CreditScoring/master/CreditScoring.csv, см. **Примечание 1**) проделайте следующее:\n",
    "\n",
    "1. Подберите наилучшие гиперпараметры для модели решающего дерева\n",
    "2. Выберите наилучшую на Ваш взгляд метрику качества для этой задачи. Объясните свой выбор\n",
    "3. Оцените качество полученного алгоритма на отложенной выборке. (\\*) Оказалось ли оно лучше ранее изученных методов классификации для этой задачи? Если да, то почему?\n",
    "4. Посмотрите, как меняется качество на трейне и тесте по мере роста максимальной глубины дерева. Наблюдаете ли Вы переобучение? Что будет, если не ограничить дерево в своих размерах (max_depth=None)? Уменьшиться ли переобучение, если увеличить параметры *min_samples_split* и/или *min_samples_leaf* (см. **Примечание 2**)? (\\*) Какие ещё гиперпараметры могут помочь в борьбе с переобучением?\n",
    "5. (\\*) Визуализируйте предсказания вашего дерева с помощью t-SNE или PCA. Сравните картинки с другими методами. Где лучше на ваш взгляд и почему?\n",
    "6. Визуализируйте полученное дерево с помощью graphviz. Глядя на первые правила у корня дерева, скажите, насколько корректными эти правила являются на ваш взгляд. Какой информационный прирост верхних трёх правил?\n",
    "\n",
    "**Примечание 1:** можно использовать любые другие данные для задачи классификации, но данные должны быть интерпретируемы - не забывайте, что в ходе этого задания вам в первую очередь требуется оценить, насколько логичным получилось дерево принятия решений!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание 2:** Подробное описание гиперпараметров дерева\n",
    "\n",
    "Озвучено и переведено с [SkLearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "* *criterion* - строковый параметр (опционален). Возможные значения: \"gini\" или \"entropy\". Смысл: критерий информативности (как мы будем оценивать, какое пороговое правило будет нам самым полезным в каждой ситуации) \n",
    "* *splitter* - строковый параметр (опционален). Как выбирать пороговое правило? Если значение \"best\", то из всех возможных пороговых правил выберется самое лучшее (долгий, но точный путь обучения). Если \"random\", то сгенерится случайное подмножество пороговых правил и выберется наилучшее из них (быстрый, но менее точный путь обучения)\n",
    "* *max_depth* - int or None, optional (default=None). Максимальная глубина, до которой мы разрешаем вырасти дереву. По умолчанию None - никаких ограничений. Влияет на переобучение. Чем больше, тем меньше шансов переобучиться (но больше шансов недообучиться)\n",
    "* *min_samples_split* - int, float, optional (default=2). Минимальное количество объектов, с которого мы продолжаем разбиение данных новыми правилами. Если в какой-то момент количество (или доля от общих, если float) объектов в узле стало меньше этого значения - мы делаем эту вершину терминальной (листом), даже если текущее разбиение не идеально. Чем больше, тем меньше шансов переобучиться (но больше шансов недообучиться)\n",
    "* *min_samples_leaf* - int, float, optional (default=1). Минимальное количество объектов в каждом листе. Смысл: если новый, классифицируемый на тесте, объект попал в терминальную вершину с одним объектом обучающей выборки, то значит ли это, что он принадлежит тому же классу? А если этот объект обучающей выборки был выбросом? Т.о., этим параметром мы так же можем регулировать риск переобучения. Чем он больше, тем меньше шансов переобучиться (но больше шансов недообучиться)\n",
    "* min_weight_fraction_leaf : float, optional (default=0.)\n",
    "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided.\n",
    "* max_features : int, float, string or None, optional (default=None). На какое количество (долю, если float) случайно взятых признаков мы будем смотреть, выбирая новое решающее правило. Нужно ли нам шерстить все пороговые правила по всем признакам каждый раз? Может, лучше взять случайным образом N признаков и искать новое правило только по ним? В точности немного рискуем потерять, зато в скорости явно выиграем! Да и в таком случае больше шансов, что больше признаков задействуется (а значит, больше шансов застраховаться от неправильных предсказаний, а значит, меньше шансов переобучиться). Также есть значение “auto” (max_features=sqrt(n_features)), “sqrt” (max_features=sqrt(n_features)), “log2” (max_features=log2(n_features)), None (max_features=n_features). Внимание: алгоритм имеет право проигнорировать этот параметр, если его недостаточно для генерации как минимум одного порогового правила! \n",
    "* *random_state* : int, RandomState instance or None, optional (default=None). Если None, то дерево будет каждый раз случайно. В противном случае псевдослучайно (каждый раз один и тот же \"случайный\" результат)\n",
    "* *max_leaf_nodes* : int or None, optional (default=None). Максимальное количество терминальных вершин (листьев). По умолчанию (None) не ограничено\n",
    "* *min_impurity_decrease* : float, optional (default=0.). Порог прироста информации, ниже которого правила не добавляются в дерево.\n",
    "* *min_impurity_split* : float, (default=1e-7). Критерий ранней остановки поддерева. Если прирост информации стал меньше заданного параметра, значит, пора остановиться и перестать расти в этом поддереве (перестать дробить выборку новыми правилами)\n",
    "* *presort* : bool, optional (default=False). Если True, то в начале дерево отсортирует данные по каждому признаку, чтобы быстрее искать пороговые правила. Влияет только на скорость обучения\n",
    "* (\\*)*class_weight* : dict, list of dicts, “balanced” or None, default=None. Вес, назначаемый каждому классу (какому классу отдавать больший приоритет при предсказании). Возможные значения параметра: Словарь {метка_класса: вес}, \"balanced\" - веса назначаются по исходному соотношению классов в обучающей выборке (чем меньше класса в выборке, тем больше его вес), None - у всех классов равный вес, список словарей (в случае, если каждый объект может принадлежать сразу нескольким классам - multilabel classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
